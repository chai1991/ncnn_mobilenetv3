{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from time import time\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_list = '/home/carsmart/users/xiaoming/yichewang/train_lst/train_train.lst'\n",
    "path_rec = '/home/carsmart/users/xiaoming/yichewang/train_lst/train_train.rec'\n",
    "val_path_list = '/home/carsmart/users/xiaoming/yichewang/train_lst/train_val.lst'\n",
    "val_path_rec = '/home/carsmart/users/xiaoming/yichewang/train_lst/train_val.rec'\n",
    "save_path = '/home/carsmart/users/xiaoming/yichewang/model/resnet50/'\n",
    "\n",
    "resize = 224\n",
    "data_shape = (3, 224, 224)\n",
    "(mean_r, mean_g, mean_b) = (0.4914, 0.4822, 0.4465)\n",
    "(std_r, std_g, std_b) = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "batch_size = 64\n",
    "ctx = [mx.gpu(1)]\n",
    "learning_rate = 0.1\n",
    "wd = 0.0001\n",
    "lr_step = 600000 // batch_size * 40\n",
    "lr_factor = 0.1\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iter(kv):\n",
    "    train_iter = mx.io.ImageRecordIter(\n",
    "        path_imglist = path_list, \n",
    "        path_imgrec = path_rec, \n",
    "        resize = resize, \n",
    "        data_shape = data_shape, \n",
    "        batch_size = batch_size, \n",
    "        rand_mirror = False, \n",
    "        rand_crop = False, \n",
    "        mean_r = mean_r, \n",
    "        mean_g = mean_g, \n",
    "        mean_b = mean_b, \n",
    "        std_r = std_r, \n",
    "        std_g = std_g, \n",
    "        std_b = std_b, \n",
    "        num_parts = kv.num_workers, \n",
    "        part_index = kv.rank, \n",
    "        shuffle = True\n",
    "    )\n",
    "    train_iter = mx.io.PrefetchingIter(train_iter)\n",
    "    \n",
    "    val_iter = mx.io.ImageRecordIter(\n",
    "        path_imglist = val_path_list, \n",
    "        path_imgrec = val_path_rec, \n",
    "        resize = resize, \n",
    "        data_shape = data_shape, \n",
    "        batch_size = batch_size, \n",
    "        rand_mirror = False, \n",
    "        rand_crop = False, \n",
    "        mean_r = mean_r, \n",
    "        mean_g = mean_g, \n",
    "        mean_b = mean_b, \n",
    "        std_r = std_r, \n",
    "        std_g = std_g, \n",
    "        std_b = std_b, \n",
    "        num_parts = kv.num_workers, \n",
    "        part_index = kv.rank\n",
    "    )\n",
    "    \n",
    "    return(train_iter, val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model define\n",
    "use model define in mxnet.gluon.model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_resnet50 = models.get_model(name = 'resnet50_v1', pretrained = False)\n",
    "def get_net():\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        net.add(net_resnet50.features)\n",
    "        net.add(nn.Dense(1062))\n",
    "    return net\n",
    "\n",
    "net = get_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## train define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch, ctx):\n",
    "    \"\"\"return data and label on ctx\"\"\"\n",
    "    if isinstance(batch, mx.io.DataBatch):\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "    else:\n",
    "        data, lable = batch\n",
    "    return (gluon.utils.split_and_load(data, ctx), \n",
    "           gluon.utils.split_and_load(label, ctx), \n",
    "           data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net, ctx = [mx.cpu()]):\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc = nd.array([0])\n",
    "    n = 0.\n",
    "    if isinstance(data_iterator, mx.io.MXDataIter):\n",
    "        data_iterator.reset()\n",
    "    for batch in data_iterator:\n",
    "        data, label, batch_size = get_batch(batch, ctx)\n",
    "        for x, y in zip(data, label):\n",
    "            acc += nd.sum(net(x).argmax(axis = 1) == y).copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc.wait_to_read() # don't push too many operators into backend\n",
    "    return acc.asscalar() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_data, val_data, net, loss, trainer, ctx, num_epochs, \n",
    "          print_batches = None, save_epochs = 10000):\n",
    "    \"\"\"train a net work\"\"\"\n",
    "    print(\"Start training on \", ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0\n",
    "        if isinstance(train_data, (mx.io.PrefetchingIter, mx.io.MXDataIter)):\n",
    "            train_data.reset()\n",
    "        start = time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data, label, batch = get_batch(batch, ctx)\n",
    "            losses = []\n",
    "            with ag.record():\n",
    "                outputs = [net(x) for x in data]\n",
    "                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "            for l in losses:\n",
    "                l.backward()\n",
    "            train_acc += sum([(yhat.argmax(axis = 1) == y).sum().asscalar() \n",
    "                             for yhat, y in zip(outputs, label)])\n",
    "            train_loss += sum([l.sum().asscalar() for l in losses])\n",
    "            trainer.step(batch_size)\n",
    "            n += batch_size\n",
    "            m += sum([y.size for y in label])\n",
    "            if print_batches and (i + 1) % print_batches == 0:\n",
    "                print(\"Data %d. Loss: %f, Train acc %f, Time %.1f sec\" % (\n",
    "                    n, train_loss / n, train_acc / m, time() - start\n",
    "                ))\n",
    "        test_acc = evaluate_accuracy(val_data, net, ctx)\n",
    "        if not epoch % save_epochs:\n",
    "            net.collect_params().save(save_path + str(epoch) + '0.params')\n",
    "        print(\"Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec\" %(\n",
    "            epoch, train_loss / n, train_acc / m, test_acc, time() - start\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  [gpu(0), gpu(1)]\n"
     ]
    }
   ],
   "source": [
    "kv = mx.kvstore.create(\"local\")\n",
    "(train_iter, val_iter) = get_iter(kv)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "lr_scheduler = mx.lr_scheduler.FactorScheduler(step = lr_step, factor = lr_factor)\n",
    "net.initialize(ctx = ctx, init = init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), \n",
    "                       'sgd', {'learning_rate': learning_rate, 'wd': wd, \n",
    "                               'lr_scheduler': lr_scheduler})\n",
    "train(train_iter, val_iter, net, loss, trainer, ctx, num_epochs = num_epochs, \n",
    "      print_batches = 1000, save_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7668 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
